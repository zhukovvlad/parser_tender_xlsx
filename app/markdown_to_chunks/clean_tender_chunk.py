"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª–µ —Å —á–∞–Ω–∫–∞–º–∏ —Ç–µ–Ω–¥–µ—Ä–∞.

–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:
–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∂–∞–µ—Ç JSON-—Ñ–∞–π–ª, –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ 'tender_chunks.json', –∫–æ—Ç–æ—Ä—ã–π
—Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —á–∞–Ω–∫–∏, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è Markdown-–æ—Ç—á–µ—Ç–∞ –æ —Ç–µ–Ω–¥–µ—Ä–µ
(–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å –ø–æ–º–æ—â—å—é langchain.text_splitter.MarkdownHeaderTextSplitter –∏–∑ –§–∞–π–ª–∞ 18).

–î–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞ —Å–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞–¥ –µ–≥–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏:
1.  –û—á–∏—Å—Ç–∫–∞ –ø–æ–ª—è "contractor": –£–¥–∞–ª—è–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å "–ü–æ–¥—Ä—è–¥—á–∏–∫:" (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ),
    –µ—Å–ª–∏ –æ–Ω –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç.
2.  –†–∞–∑–±–æ—Ä –ø–æ–ª—è "position": –ï—Å–ª–∏ –ø–æ–ª–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ "N. **–ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏**...",
    –∏–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä ("position_number") –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ ("position_title") –ø–æ–∑–∏—Ü–∏–∏.
3.  –†–∞–∑–±–æ—Ä –ø–æ–ª—è "section": –ï—Å–ª–∏ –ø–æ–ª–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ "üìò –†–∞–∑–¥–µ–ª N: –ù–∞–∑–≤–∞–Ω–∏–µ...",
    –∏–∑–≤–ª–µ–∫–∞–µ—Ç ID —Ä–∞–∑–¥–µ–ª–∞ ("section_id") –∏, –µ—Å–ª–∏ –µ—Å—Ç—å, –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞ ("section_title").

–†–µ–∑—É–ª—å—Ç–∞—Ç (—Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏) —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è
–≤ –Ω–æ–≤—ã–π JSON-—Ñ–∞–π–ª 'tender_chunks_cleaned.json'.

–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª ('tender_chunks.json') –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—Ç—å —Å–æ–±–æ–π JSON-–º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤,
–≥–¥–µ –∫–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç –∏–º–µ–µ—Ç –∫–ª—é—á–∏ "text" (—Å—Ç—Ä–æ–∫–∞) –∏ "metadata" (—Å–ª–æ–≤–∞—Ä—å).
–ö–ª—é—á–∏ "contractor", "position", "section" –≤ —Å–ª–æ–≤–∞—Ä–µ "metadata" —è–≤–ª—è—é—Ç—Å—è –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏.

–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª ('tender_chunks_cleaned.json') –±—É–¥–µ—Ç –∏–º–µ—Ç—å —Ç—É –∂–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É,
–Ω–æ —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–º–∏ –∏–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø–æ–ª—è–º–∏ –≤ "metadata".
"""

import re
import json
from typing import List, Dict, Any, Optional

# –ò–º–µ–Ω–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ –∏ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–æ–≤ –∂–µ—Å—Ç–∫–æ –∑–∞–¥–∞–Ω—ã –≤ —Å–∫—Ä–∏–ø—Ç–µ
INPUT_FILENAME = "tender_chunks.json"
OUTPUT_FILENAME = "tender_chunks_cleaned.json"


def clean_and_parse_chunk_metadata(
    chunks_data: List[Dict[str, Any]],
) -> List[Dict[str, Any]]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤, –æ—á–∏—â–∞—è –∏ –¥–æ–ø–æ–ª–Ω—è—è –∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ.

    Args:
        chunks_data: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π, –≥–¥–µ –∫–∞–∂–¥—ã–π —Å–ª–æ–≤–∞—Ä—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —á–∞–Ω–∫
                     —Å –∫–ª—é—á–∞–º–∏ "text" –∏ "metadata".

    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏.
    """
    processed_chunks: List[Dict[str, Any]] = []

    for chunk in chunks_data:
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –∫–ª—é—á–∏ "text" –∏ "metadata" –≤—Å–µ–≥–¥–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç.
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –æ–±—ä–µ–∫—Ç —á–∞–Ω–∫–∞,
        # –µ—Å–ª–∏ chunks_data –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≥–¥–µ-—Ç–æ –µ—â–µ (—Ö–æ—Ç—è –≤ –¥–∞–Ω–Ω–æ–º —Å–∫—Ä–∏–ø—Ç–µ —ç—Ç–æ –Ω–µ —Ç–∞–∫).
        # –û–¥–Ω–∞–∫–æ, –µ—Å–ª–∏ —á–∞–Ω–∫–∏ –±–æ–ª—å—à–∏–µ, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ.
        # –í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ, –∏—Å—Ö–æ–¥–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª 'meta' –Ω–∞ –º–µ—Å—Ç–µ –∏ –¥–æ–±–∞–≤–ª—è–ª
        # –Ω–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å –≤ cleaned_chunks. –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ.
        meta = chunk.get("metadata", {}).copy()  # –†–∞–±–æ—Ç–∞–µ–º —Å –∫–æ–ø–∏–µ–π –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        text_content = chunk.get("text", "")

        # 1. –û—á–∏—Å—Ç–∫–∞ –ø–æ–ª—è "contractor"
        contractor_val: Optional[str] = meta.get("contractor")
        if contractor_val and isinstance(contractor_val, str):
            # –†–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞ "–ü–æ–¥—Ä—è–¥—á–∏–∫:" –∏ –ø—Ä–æ–±–µ–ª–æ–≤ –≤–æ–∫—Ä—É–≥
            match_contractor_prefix = re.match(
                r"–ü–æ–¥—Ä—è–¥—á–∏–∫:\s*(.*)", contractor_val, re.IGNORECASE
            )
            if match_contractor_prefix:
                meta["contractor"] = match_contractor_prefix.group(1).strip()
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ, –µ—Å–ª–∏ –≤—Å–µ–≥–¥–∞ "–ü–æ–¥—Ä—è–¥—á–∏–∫:" —Å –±–æ–ª—å—à–æ–π –±—É–∫–≤—ã, –∫–∞–∫ –≤ –≤–∞—à–µ–º replace:
            # if contractor_val.lower().startswith("–ø–æ–¥—Ä—è–¥—á–∏–∫:"):
            #     # –£–¥–∞–ª—è–µ–º —Ç–æ—á–Ω—É—é –¥–ª–∏–Ω—É –ø—Ä–µ—Ñ–∏–∫—Å–∞ "–ü–æ–¥—Ä—è–¥—á–∏–∫:" (10 —Å–∏–º–≤–æ–ª–æ–≤)
            #     meta["contractor"] = contractor_val[len("–ü–æ–¥—Ä—è–¥—á–∏–∫:"):].strip()

        # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—è "position"
        position_val: Optional[str] = meta.get("position")
        if position_val and isinstance(position_val, str):
            # –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä–æ–∫–∏: '6. **–ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏** (–æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ä–∞–∑–¥–µ–ª—É 2)'
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ (—Ç–µ–∫—Å—Ç –º–µ–∂–¥—É **)
            match_position = re.match(r"(\d+)\.\s+\*\*(.*?)\*\*", position_val.strip())
            if match_position:
                try:
                    meta["position_number"] = int(match_position.group(1))
                    meta["position_title"] = match_position.group(2).strip()
                except ValueError:
                    # –ï—Å–ª–∏ –Ω–æ–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ int, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    print(
                        f"Warning: Could not parse position_number from '{match_position.group(1)}'"
                    )

        # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—è "section"
        section_val: Optional[str] = meta.get("section")
        if section_val and isinstance(section_val, str):
            # –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä–æ–∫–∏: 'üìò –†–∞–∑–¥–µ–ª 1: –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞' –∏–ª–∏ 'üìò –†–∞–∑–¥–µ–ª 1'
            # –ò–∑–≤–ª–µ–∫–∞–µ–º ID —Ä–∞–∑–¥–µ–ª–∞ –∏, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏–µ
            match_section = re.match(
                r"üìò\s*–†–∞–∑–¥–µ–ª\s*(\d+)(?::\s*(.*))?", section_val.strip()
            )
            if match_section:
                try:
                    meta["section_id"] = int(match_section.group(1))
                    # –ï—Å–ª–∏ –µ—Å—Ç—å –≤—Ç–æ—Ä–∞—è –≥—Ä—É–ø–ø–∞ (–Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞ –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è)
                    if match_section.group(2) and match_section.group(2).strip():
                        meta["section_title"] = match_section.group(2).strip()
                except ValueError:
                    print(
                        f"Warning: Could not parse section_id from '{match_section.group(1)}'"
                    )

        processed_chunks.append(
            {"text": text_content, "metadata": meta}  # –î–æ–±–∞–≤–ª—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        )

    return processed_chunks


def main():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞: –∑–∞–≥—Ä—É–∑–∫–∞, –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤.
    """
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {INPUT_FILENAME}...")
    try:
        with open(INPUT_FILENAME, "r", encoding="utf-8") as f:
            chunks_from_file: List[Dict[str, Any]] = json.load(f)
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª '{INPUT_FILENAME}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return
    except json.JSONDecodeError:
        print(f"–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å JSON –∏–∑ —Ñ–∞–π–ª–∞ '{INPUT_FILENAME}'.")
        return

    print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(chunks_from_file)} —á–∞–Ω–∫–æ–≤...")
    cleaned_chunks_data = clean_and_parse_chunk_metadata(chunks_from_file)

    print(
        f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(cleaned_chunks_data)} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –≤ {OUTPUT_FILENAME}..."
    )
    try:
        with open(OUTPUT_FILENAME, "w", encoding="utf-8") as f:
            json.dump(cleaned_chunks_data, f, ensure_ascii=False, indent=2)
        print("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
    except IOError:
        print(f"–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª '{OUTPUT_FILENAME}'.")


if __name__ == "__main__":
    main()
