# Парсер и анализатор тендерной документации с использованием LLM

## Описание

Этот проект представляет собой комплексный пайплайн на Python для извлечения данных из структурированных Excel-файлов (XLSX) тендерной документации и их последующего интеллектуального анализа с использованием больших языковых моделей (LLM).

Основная цель — автоматизировать не только получение структурированных данных из таблиц, но и их смысловую обработку: автоматическую **категоризацию** каждого лота и **извлечение ключевых технических параметров** в зависимости от его категории.

## Общий процесс обработки данных

Пайплайн состоит из двух основных этапов:

1.  **Этап 1: Первичная обработка и генерация отчетов (`parse.py`)**
    * Исходный XLSX-файл обрабатывается скриптом `parse.py`.
    * Данные извлекаются, проходят постобработку (нормализация структуры, очистка) и сохраняются в итоговый JSON-файл (`<имя_файла>.json`).
    * На основе этого JSON генерируется два вида отчетов в формате Markdown:
        * Один **общий отчет** по всему тендеру (`<имя_файла>.md`).
        * **Детализированные отчеты по позициям для каждого лота** (`<имя_файла>_<номер_лота>_positions.md`). Эти файлы служат входными данными для следующего этапа.

2.  **Этап 2: Интеллектуальный анализ лотов (`llm_test.py`)**
    * Скрипт `llm_test.py` берет на вход один из детализированных отчетов по лоту.
    * **Категоризация лота:** Скрипт отправляет краткую информацию о лоте в LLM для определения его основной категории (например, "нулевой цикл", "инженерные сети"). Применяется двухэтапная логика: быстрая проверка и, при необходимости, детальный анализ каждой позиции.
    * **Извлечение параметров:** На основе полученной категории выбирается специализированный промпт. Скрипт в пакетном режиме обрабатывает все позиции лота, извлекая конкретные технические параметры (например, толщину стен, объемы бетона и т.д.).
    * Результат анализа сохраняется в отдельный JSON-файл, содержащий структурированный список извлеченных параметров.

## Структура проекта

* `parse.py`: Главный скрипт для парсинга XLSX, постобработки и генерации всех JSON и Markdown отчетов.
* `llm_test.py`: Главный скрипт для интеллектуального анализа детализированных отчетов по лотам с помощью LLM.
* `prompts.py`: Модуль, содержащий все системные промпты для взаимодействия с LLM (классификация, извлечение параметров).
* `constants.py`: Файл, определяющий строковые константы, используемые в проекте.
* `helpers/`: Директория со вспомогательными модулями для парсинга XLSX и постобработки JSON.
* `markdown_utils/`: Директория для утилит, связанных с Markdown (`json_to_markdown.py`, `positions_report.py`).
* `requirements.txt`: Файл со списком всех необходимых Python-библиотек.
* `README.md`: Данный файл.

## Требования

* Python 3.x (рекомендуется 3.9+)
* Все необходимые библиотеки перечислены в `requirements.txt`. Ключевые зависимости: `openpyxl`, `requests`, `python-dotenv`.

## Установка

1.  Клонируйте репозиторий:
    ```bash
    git clone <URL_вашего_репозитория>
    cd <директория_репозитория>
    ```
2.  Создайте и активируйте виртуальное окружение:
    ```bash
    python -m venv venv
    # Linux/macOS: source venv/bin/activate
    # Windows: venv\Scripts\activate
    ```
3.  Установите зависимости:
    ```bash
    pip install -r requirements.txt
    ```
4.  Создайте файл `.env` в корне проекта и укажите в нем параметры для подключения к LLM:
    ```env
    OLLAMA_URL="http://localhost:11434/api/chat"
    OLLAMA_MODEL="mistral"
    OLLAMA_TOKEN="" # Опционально
    ```

## Использование

Процесс обработки данных состоит из двух последовательных шагов:

1.  **Запуск `parse.py` для подготовки данных:**
    Скрипт принимает один аргумент — путь к исходному XLSX файлу.
    ```bash
    python parse.py ./data/tender_document.xlsx
    ```
    Это создаст все необходимые JSON и MD файлы и переместит их в папки `tenders_json/`, `tenders_md/`, `tenders_positions/`.

2.  **Запуск `llm_test.py` для анализа конкретного лота:**
    Скрипт использует файл `.env` для настроек и по умолчанию обрабатывает файл, указанный в нем (`INPUT_FILE`).
    ```bash
    python llm_test.py
    ```
    Результат будет сохранен в папку `tender_categories/` (или другую, указанную в `Config`).

## Формат выходных данных

### Результат `parse.py`

* `<имя_файла>.json`: JSON с полной структурированной информацией по тендеру.
* `<имя_файла>.md`: Общий Markdown-отчет.
* `<имя_файла>_<номер_лота>_positions.md`: Детализированные отчеты по каждому лоту, готовые для анализа.

### Результат `llm_test.py`

* JSON-файл в папке `tender_categories/`, содержащий список извлеченных параметров. Каждый элемент списка — это объект вида:
    ```json
    {
      "category": "нулевой цикл",
      "parameter": "толщина стены в грунте",
      "value": 600,
      "unit": "мм"
    }
    ```

## Возможные дальнейшие шаги

Данные, извлеченные в результате работы пайплайна, идеально подходят для:

1.  **Загрузки в реляционную базу данных:** Для построения аналитических отчетов, дашбордов и сравнения технических параметров по разным тендерам.
2.  **Создания аналитических систем:** Для автоматического поиска тендеров с определенными параметрами (например, "все тендеры, где толщина стены в грунте > 500 мм").
3.  **Обучения собственных моделей:** Для прогнозирования стоимости работ на основе извлеченных параметров.

## Важные замечания и возможные улучшения

* **Асинхронность:** Для ускорения работы скрипта `llm_test.py` можно перевести его на асинхронные запросы (`asyncio` + `aiohttp`), что позволит обрабатывать батчи параллельно.
* **Агрегация результатов:** Вместо создания отдельного файла с параметрами для каждого запуска, можно реализовать логику сбора результатов по всем лотам в один итоговый файл.
* **Унификация констант и конфигурации:** Продолжать выносить "магические" значения в `constants.py` и файлы конфигурации.
* **Логирование и тесты:** Расширить логирование для более детальной отладки и написать модульные тесты для ключевых функций.