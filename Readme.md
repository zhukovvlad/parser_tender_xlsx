# Парсер тендерной документации XLSX и подготовка данных

## Описание

Этот проект представляет собой набор Python-скриптов для извлечения данных из структурированных Excel-файлов (XLSX), предположительно тендерной документации, их преобразования в формат JSON и последующей постобработки для подготовки данных к анализу и хранению.

Проект нацелен на автоматизацию получения структурированной информации, включая обработку различных секций документа, объединенных ячеек, и нормализацию данных для дальнейшего использования в базах данных и аналитических системах.

## Общий процесс обработки данных

1.  **Парсинг XLSX в JSON:** Исходный Excel-файл (который, как предполагается, генерируется автоматически и имеет строгую структуру) обрабатывается скриптом `parse.py`. На выходе получается "сырой" JSON-файл, отражающий структуру тендерного документа.
2.  **Постобработка JSON:** Полученный JSON-файл далее обрабатывается функциями из модуля `helpers/postprocess.py`. Эти функции выполняют:
    * Нормализацию структуры лотов и предложений, включая выделение "Расчетной стоимости" как базового предложения и обработку связанных с этим полей (см. `normalize_lots_json_structure`).
    * Очистку данных от строковых представлений ошибок деления на ноль (см. `replace_div0_with_null`).
    * На выходе получается "очищенный" и нормализованный JSON, готовый для загрузки в базы данных или для других аналитических задач.

## Структура проекта

* `parse.py`: Главный скрипт для первоначального парсинга XLSX в JSON.
* `helpers/`: Директория, содержащая вспомогательные модули:
    * Модули для парсинга различных частей документа (например, `read_headers.py`, `read_lots_and_boundaries.py`, и т.д.).
    * `postprocess.py`: Модуль, содержащий функции для постобработки JSON-данных, сгенерированных `parse.py`.
* `requirements.txt`: Файл, содержащий список всех необходимых Python-библиотек.

## Требования

* Python 3.x
* Все необходимые Python-библиотеки перечислены в файле `requirements.txt`. Ключевой зависимостью является `openpyxl` для работы с XLSX файлами.

## Установка

1.  Клонируйте репозиторий (если он уже создан):
    ```bash
    git clone <URL_вашего_репозитория>
    cd <директория_репозитория>
    ```
2.  Рекомендуется создать и активировать виртуальное окружение:
    ```bash
    python -m venv venv
    # Linux/macOS:
    source venv/bin/activate
    # Windows:
    # venv\Scripts\activate
    ```
3.  Установите все необходимые зависимости из файла `requirements.txt`:
    ```bash
    pip install -r requirements.txt
    ```

## Использование

Процесс обработки данных обычно состоит из двух шагов:

1.  **Парсинг XLSX в "сырой" JSON с помощью `parse.py`:**
    ```bash
    python parse.py <путь_к_входному_XLSX_файлу> <путь_к_raw_json_файлу>
    ```
    **Пример:**
    ```bash
    python parse.py ./data/tender_document.xlsx ./output/raw_tender.json
    ```

2.  **Постобработка "сырого" JSON:**
    Функции из `helpers/postprocess.py` вызываются программно для обработки JSON, полученного на шаге 1.
    Пример такого вызова в вашем основном управляющем коде может выглядеть так:
    ```python
    # import json
    # from helpers.postprocess import normalize_lots_json_structure, replace_div0_with_null

    # # Загрузка "сырого" JSON
    # with open("./output/raw_tender.json", "r", encoding="utf-8") as f:
    #     data = json.load(f)

    # # Применение функций постобработки
    # data = normalize_lots_json_structure(data)
    # data = replace_div0_with_null(data)

    # # Сохранение финального JSON
    # with open("./output/final_tender.json", "w", encoding="utf-8") as f:
    #     json.dump(data, f, ensure_ascii=False, indent=2)
    ```
    Вам нужно будет интегрировать этот шаг в ваш рабочий процесс в соответствии с архитектурой вашего приложения.

## Описание модулей/файлов

### `parse.py`
Основной скрипт, который оркестрирует процесс извлечения данных из XLSX файла и их первичную структуризацию в JSON. Использует модули из директории `helpers`.

### `helpers/` (вспомогательные модули)
* **Модули парсинга (например, `read_headers.py`, `get_positions.py` и т.д.)**:
    * `build_merged_shape_map.py`: Строит карту объединенных ячеек.
    * `find_row_by_first_column.py`: Находит строку по тексту в первой колонке.
    * `get_additional_info.py`: Извлекает дополнительную информацию о подрядчике.
    * `get_items_dict.py`: Генерирует шаблон для позиций работ/материалов.
    * `get_positions.py`: Извлекает товарные позиции и итоговые строки для подрядчика.
    * `get_proposals.py`: Собирает предложения подрядчиков.
    * `parse_contractor_row.py`: Парсит одну строку данных подрядчика.
    * `read_contractors.py`: Считывает информацию о заголовках контрагентов.
    * `read_executer_block.py`: Считывает информацию об исполнителе документа.
    * `read_headers.py`: Считывает заголовки документа (ID тендера, название и т.д.).
    * `read_lots_and_boundaries.py`: Считывает информацию о лотах.
* **`postprocess.py` (модуль постобработки JSON)**:
    * **`normalize_lots_json_structure(data)`**:
        * Переносит предложение "Расчетная стоимость" из общего списка предложений в отдельное поле `baseline_proposal` внутри каждого лота.
        * Переиндексирует ключи для остальных предложений подрядчиков.
        * Удаляет поле `"Дополнительная информация"` из извлеченного `baseline_proposal`.
        * Если "Расчетная стоимость" (`baseline`) не найдена, или если в ее `items['summary']` все значения в блоках "стоимость всего" эквивалентны нулю/None, то `lot['baseline_proposal']` устанавливается в `{"name": "Расчетная стоимость отсутствует"}`. В этом же случае, у всех остальных ("реальных") подрядчиков в данном лоте из каждой их позиции и итоговой строки удаляется поле `"отклонение от расчетной стоимости"`.
        * В противном случае, `lot['baseline_proposal']` содержит обработанный объект "Расчетной стоимости" (включая ключ "items").
    * **`replace_div0_with_null(data)`**:
        * Рекурсивно обходит всю структуру JSON (словари, списки).
        * Заменяет строковые значения, представляющие ошибки деления на ноль (например, 'DIV/0', '#DIV/0!', 'деление на 0'), на значение `None`.

## Формат входных данных (XLSX)

Скрипт `parse.py` ожидает на вход XLSX файл, сгенерированный автоматизированной системой, что предполагает **строго определенную и стабильную структуру документа**. Расположение ключевых полей, заголовков секций, данных о подрядчиках и лотах должно точно соответствовать логике, заложенной в функциях парсинга.

## Формат выходных данных (JSON)

После выполнения парсинга (`parse.py`) и всех шагов постобработки (функциями из `helpers/postprocess.py`), итоговый JSON-файл будет иметь следующую структуру (основные моменты):

* Ключи верхнего уровня, соответствующие заголовкам документа (ID тендера, название, объект, адрес).
* `"executor"`: Информация об исполнителе.
* `"lots"`: Словарь лотов. Каждый лот (`"lot_X"`) содержит:
    * `"lot_title"`: Название лота.
    * `"baseline_proposal"`: Либо объект "Расчетной стоимости" (содержащий "name", "items" с детализацией, и другие поля, но без "Дополнительная информация"), либо объект `{"name": "Расчетная стоимость отсутствует"}`.
    * `"proposals"`: Словарь с переиндексированными предложениями других подрядчиков. Если `baseline_proposal` отсутствовал или был "пустым", у этих подрядчиков из их позиций и итоговых строк будет удалено поле `"отклонение от расчетной стоимости"`.
* Все строковые значения, ранее обозначавшие ошибку деления на ноль, будут заменены на `null` (JSON-эквивалент Python `None`).

## Возможные дальнейшие шаги и применение данных

Данные, подготовленные этим проектом, могут быть использованы для:

1.  **Загрузки в реляционную базу данных (RDBMS):** Для структурированного хранения, выполнения точных запросов, построения отчетов и традиционного анализа.
2.  **Создания эмбеддингов для векторной базы данных:**
    * Преобразование JSON (или его текстовых частей) в формат Markdown (.md).
    * Генерация векторных представлений (эмбеддингов) этих .md файлов.
    * Загрузка эмбеддингов в векторную БД.
3.  **Реализации "интеллектуальных" функций:**
    * Семантическое сравнение тендеров между собой.
    * Проведение углубленного исторического анализа по различным видам работ и условиям.
    * Поиск похожих тендеров или позиций.

## Возможные улучшения (для данного проекта парсинга/постобработки)

* **Конфигурация:** Вынесение настроек (например, стартовые строки для чтения секций, ключи для поиска, список ошибок деления на ноль) в конфигурационные файлы.
* **Обработка ошибок:** Более детальная обработка возможных ошибок при парсинге и постобработке, включая более информативные сообщения.
* **Логирование:** Использование модуля `logging` для записи информации о ходе выполнения, предупреждениях и ошибках.
* **Модульные тесты:** Написание тестов для проверки корректности работы отдельных функций парсинга и постобработки.
* **CLI для `parse.py` и `postprocess.py`:** Если требуется более гибкий запуск, можно улучшить интерфейсы командной строки для обоих этапов.

---