# Парсер тендерной документации XLSX и подготовка данных для AI

## Описание

Этот проект представляет собой набор Python-скриптов для извлечения данных из структурированных Excel-файлов (XLSX), предположительно тендерной документации. Он выполняет их преобразование в формат JSON, генерирует Markdown-отчет, а затем подготавливает текстовые данные для использования в AI-приложениях, таких как системы RAG (Retrieval Augmented Generation), путем их разделения на чанки.

Проект нацелен на автоматизацию получения структурированной информации, включая обработку различных секций документа, объединенных ячеек, нормализацию данных и их последующую подготовку для анализа, хранения и использования в моделях машинного обучения.

## Общий процесс обработки данных

1.  **Парсинг XLSX, постобработка, сохранение JSON и генерация Markdown:** Исходный Excel-файл обрабатывается основным скриптом `parse.py`. Этот скрипт:
    * Извлекает данные из XLSX.
    * Применяет функции постобработки из `helpers/postprocess.py` (нормализация структуры лотов, выделение "Расчетной стоимости", очистка ошибок деления на ноль).
    * Сохраняет итоговый, обработанный JSON-файл.
    * Генерирует детализированный Markdown-отчет на основе обработанного JSON с помощью `markdown_utils/json_to_markdown.py`.
2.  **Разделение Markdown-отчета на чанки:** Сгенерированный Markdown-файл обрабатывается скриптом (на основе файла 18, условно `scripts/split_markdown_for_embedding.py`). Этот скрипт использует `langchain` для разделения текста на смысловые чанки на основе заголовков. Результат сохраняется в JSON-файл (`tender_chunks.json`).
3.  **Очистка чанков:** Полученный JSON-файл с чанками (`tender_chunks.json`) далее обрабатывается скриптом (на основе файла 15, условно `scripts/clean_embedding_chunks.py`). Этот скрипт выполняет дополнительную очистку метаданных этих чанков. Результат сохраняется в новый JSON-файл (`tender_chunks_cleaned.json`), который предполагается использовать для создания эмбеддингов и загрузки в векторную базу данных.

## Структура проекта

* `parse.py`: Главный скрипт для парсинга XLSX, постобработки, сохранения JSON и генерации Markdown.
* `constants.py`: Файл, определяющий все строковые константы, используемые в проекте.
* `helpers/`: Директория, содержащая вспомогательные модули для парсинга и постобработки:
    * Модули для парсинга различных частей документа (например, `read_headers.py`, `get_positions.py`, и т.д.).
    * `postprocess.py`: Модуль с функциями для постобработки извлеченных JSON-данных.
* `markdown_utils/`: Директория для утилит, связанных с Markdown.
    * `json_to_markdown.py`: Модуль для преобразования JSON в Markdown-отчет.
* `scripts/` (предполагаемое имя директории):
    * `split_markdown_for_embedding.py` (условное имя для файла 18): Скрипт для разделения Markdown на чанки с использованием Langchain.
    * `clean_embedding_chunks.py` (условное имя для файла 15): Скрипт для очистки метаданных чанков.
* `requirements.txt`: Файл, содержащий список всех необходимых Python-библиотек.
* `README.md`: Данный файл.

## Требования

* Python 3.x (рекомендуется 3.9+)
* Все необходимые Python-библиотеки перечислены в файле `requirements.txt`. Ключевыми зависимостями являются `openpyxl` для работы с XLSX файлами и `langchain` для обработки текста.

## Установка

1.  Клонируйте репозиторий (если он уже создан):
    ```bash
    git clone <URL_вашего_репозитория>
    cd <директория_репозитория>
    ```
2.  Рекомендуется создать и активировать виртуальное окружение:
    ```bash
    python -m venv venv
    # Linux/macOS:
    source venv/bin/activate
    # Windows:
    # venv\Scripts\activate
    ```
3.  Установите все необходимые зависимости из файла `requirements.txt`:
    ```bash
    pip install -r requirements.txt
    ```

## Использование

Процесс обработки данных обычно состоит из трех шагов:

1.  **Парсинг XLSX, обработка, сохранение JSON и генерация Markdown с помощью `parse.py`:**
    ```bash
    python parse.py <путь_к_входному_XLSX_файлу> <путь_к_выходному_JSON_файлу>
    ```
    Markdown-файл будет сохранен рядом с выходным JSON-файлом с тем же именем, но расширением `.md`.
    **Пример:**
    ```bash
    python parse.py ./data/tender_document.xlsx ./output/final_tender.json
    # Это создаст ./output/final_tender.json и ./output/final_tender.md
    ```

2.  **Разделение Markdown-отчета на чанки (скрипт на основе файла 18):**
    Предположим, скрипт называется `scripts/split_markdown_for_embedding.py`.
    ```bash
    python scripts/split_markdown_for_embedding.py <путь_к_Markdown_файлу> <путь_к_JSON_файлу_с_чанками>
    ```
    **Пример:**
    ```bash
    python scripts/split_markdown_for_embedding.py ./output/final_tender.md ./output/tender_chunks.json
    ```

3.  **Очистка чанков (скрипт на основе файла 15):**
    Предположим, скрипт называется `scripts/clean_embedding_chunks.py`.
    ```bash
    python scripts/clean_embedding_chunks.py <путь_к_JSON_с_чанками> <путь_к_очищенному_JSON_с_чанками>
    ```
    **Пример:**
    ```bash
    python scripts/clean_embedding_chunks.py ./output/tender_chunks.json ./output/tender_chunks_cleaned.json
    ```

## Описание модулей/файлов

### `parse.py`
Основной скрипт, который оркестрирует весь процесс: от извлечения данных из XLSX файла и их полной обработки (включая вызовы функций из `helpers/postprocess.py`) до сохранения финального JSON и генерации Markdown-отчета (с помощью `markdown_utils/json_to_markdown.py`).

### `constants.py`
Содержит все строковые константы, используемые в проекте для ключей JSON, текстовых маркеров для парсинга и т.д. **Важно:** содержит дублирующиеся определения некоторых констант, которые следует унифицировать.

### `helpers/` (вспомогательные модули)
* `build_merged_shape_map.py`: Строит карту размеров объединенных ячеек на листе Excel.
* `find_row_by_first_column.py`: Ищет строку на листе Excel по значению в первой ячейке.
* `get_additional_info.py`: Извлекает структурированную дополнительную информацию о подрядчике.
* `get_items_dict.py`: Возвращает шаблонный словарь для представления одной позиции работ/материалов.
* `get_positions.py`: Извлекает все детализированные позиции и итоговые строки, относящиеся к подрядчику.
* `get_proposals.py`: Извлекает и структурирует данные по предложениям всех подрядчиков.
* `parse_contractor_row.py`: Извлекает значения, относящиеся к подрядчику, из одной строки листа.
* `read_contractors.py`: Ищет и извлекает информацию о заголовках контрагентов.
* `read_executer_block.py`: Извлекает информацию об исполнителе из нижней части листа.
* `read_headers.py`: Извлекает заголовочную информацию (ID тендера, название и т.д.).
* `read_lots_and_boundaries.py`: Извлекает информацию о лотах.
* `sanitize_text.py` (Файл 13): Утилита для очистки текста от нежелательных символов.
* **`postprocess.py` (модуль постобработки JSON)**:
    * **`normalize_lots_json_structure(data)`**:
        * Переносит предложение "Расчетная стоимость" в отдельное поле `baseline_proposal`.
        * Переиндексирует ключи для остальных предложений подрядчиков.
        * Удаляет "Дополнительную информацию" из `baseline_proposal`.
        * Обрабатывает случаи отсутствия или "пустоты" `baseline_proposal`, корректируя данные у других подрядчиков (удаление поля "отклонение от расчетной стоимости").
        * Применяет `annotate_structure_fields` для добавления иерархии в позиции.
    * **`replace_div0_with_null(data)`**: Рекурсивно заменяет строковые ошибки деления на ноль на `None`.
    * **`annotate_structure_fields(positions)`**: Добавляет поля "is_chapter" и "chapter_ref" в позиции для иерархического представления.

### `markdown_utils/json_to_markdown.py` (Файл 14)
Преобразует итоговый JSON-объект в структурированный Markdown-файл, поддерживая иерархическое отображение позиций.

### `scripts/split_markdown_for_embedding.py` (условное имя для файла 18)
Использует `langchain.text_splitter.MarkdownHeaderTextSplitter` для разделения Markdown-отчета на чанки, сохраняя их вместе с метаданными в JSON-формате (`tender_chunks.json`).

### `scripts/clean_embedding_chunks.py` (условное имя для файла 15)
Читает `tender_chunks.json`, выполняет очистку и возможное преобразование метаданных в этих чанках и сохраняет результат в `tender_chunks_cleaned.json`.

## Формат входных данных (XLSX)

Скрипт `parse.py` ожидает на вход XLSX файл, который, как предполагается, имеет **строго определенную и стабильную структуру**. Расположение ключевых полей, заголовков секций, данных о подрядчиках и лотах должно точно соответствовать логике, заложенной в функциях парсинга.

## Формат выходных данных (JSON)

После выполнения `parse.py` (который включает парсинг и все шаги постобработки), итоговый JSON-файл (`final_tender.json` в примере) будет иметь следующую структуру (основные моменты):

* Ключи верхнего уровня, соответствующие заголовкам документа (ID тендера, название, объект, адрес).
* `"executor"`: Информация об исполнителе.
* `"lots"`: Словарь лотов. Каждый лот (`"lot_X"`) содержит:
    * `"lot_title"`: Название лота.
    * `"baseline_proposal"`: Либо объект "Расчетной стоимости", либо объект `{"title": "Расчетная стоимость отсутствует"}` (поле `name` было заменено на `title` для консистентности с другими предложениями в `normalize_lots_json_structure`, если `title` это ключ для имени контрагента).
    * `"proposals"`: Словарь с переиндексированными предложениями других подрядчиков. Каждое предложение содержит метаданные подрядчика, его позиции (`contractor_items` -> `positions`), итоговые суммы (`contractor_items` -> `summary`) и дополнительную информацию. Если `baseline_proposal` отсутствовал или был "пустым", у этих подрядчиков из их позиций и итоговых строк будет удалено поле, связанное с отклонением от расчетной стоимости.
    * Все позиции подрядчиков будут аннотированы полями `is_chapter` и `chapter_ref`.
* Все строковые значения, ранее обозначавшие ошибку деления на ноль, будут заменены на `null`.

## Возможные дальнейшие шаги и применение данных

Данные, подготовленные этим проектом (`final_tender.json` и особенно `tender_chunks_cleaned.json`), могут быть использованы для:

1.  **Загрузки в реляционную базу данных (RDBMS):** Для структурированного хранения, выполнения точных запросов, построения отчетов и традиционного анализа (используя `final_tender.json`).
2.  **Создания эмбеддингов для векторной базы данных (используя `tender_chunks_cleaned.json`):**
    * Генерация векторных представлений (эмбеддингов) для текстового содержимого каждого чанка.
    * Загрузка эмбеддингов и их метаданных в векторную БД.
3.  **Реализации "интеллектуальных" функций на основе RAG:**
    * Семантический поиск по тендерной документации.
    * Ответы на вопросы по содержимому тендеров.
    * Сравнительный анализ тендеров, подрядчиков или отдельных позиций.
    * Автоматическая суммаризация.

## Важные замечания и возможные улучшения

* **Устранение дублирования констант:** В файле `constants.py` присутствуют дублирующиеся определения для некоторых ключей. Это необходимо исправить для предсказуемой работы системы.
* **Конфигурация:** Вынесение настроек (например, стартовые строки для чтения секций, ключи для поиска, список ошибок деления на ноль) в конфигурационные файлы.
* **Обработка ошибок:** Более детальная обработка возможных ошибок при парсинге и постобработке, включая более информативные сообщения.
* **Логирование:** Использование модуля `logging` для записи информации о ходе выполнения, предупреждениях и ошибках.
* **Модульные тесты:** Написание тестов для проверки корректности работы отдельных функций парсинга и постобработки.
* **Уточнение имен скриптов:** Для скриптов (файлы 15 и 18) следует присвоить конкретные имена файлов и обновить их в документации и, возможно, в структуре проекта (например, поместив в директорию `scripts/`).
* **Управление зависимостями:** Для `langchain` и других библиотек с активным развитием может быть полезно зафиксировать конкретные версии в `requirements.txt` после проверки совместимости, чтобы обеспечить воспроизводимость окружения.

---